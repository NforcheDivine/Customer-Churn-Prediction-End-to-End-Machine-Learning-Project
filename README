# Customer Churn Prediction – End-to-End Machine Learning Project

## 1. Business Context

Customer churn represents a major cost to subscription and service-based businesses.
Acquiring a new customer is typically 5–7 times more expensive than retaining an existing one.
The objective of this project is to build a predictive model capable of identifying customers at risk of churning so that targeted retention strategies can be deployed proactively.

This project simulates a real-world analytics engagement where a data scientist must:

- integrate multiple operational data sources
- explore behavioural signals
- engineer meaningful features
- prevent data leakage
- deliver an interpretable baseline model
- provide actionable insights rather than just metrics

---

## 2. Dataset Description

The dataset combines information from several business domains:

- **Customer demographics** – age, gender, marital status, income level
- **Transaction history** – spending behaviour, product categories
- **Customer service interactions** – complaints, feedback, resolution status
- **Digital engagement** – login frequency, service usage channels
- **Temporal activity** – last login, last interaction, last transaction

### Target Variable
`ChurnStatus`
- 1 = customer churned
- 0 = customer retained

### Key Challenges
- Moderate class imbalance (~20% churn)
- Presence of raw date fields with leakage risk
- Mixed numeric and categorical features
- Missing values across several attributes

---

## 3. Methodology

### 3.1 Exploratory Data Analysis

EDA focused on:

- distribution of key behavioural metrics
- churn rate across demographic segments
- missing value patterns
- relationship between engagement recency and churn
- identification of anomalies and outliers

All visual outputs are stored in `/plots`.

---

### 3.2 Leakage Detection & Feature Engineering

Initial experiments revealed that **raw date variables introduced data leakage** by implicitly encoding future information.
These were replaced with valid, business-meaningful features:

- `DaysSinceLastLogin`
- `DaysSinceLastInteraction`
- `DaysSinceLastTransaction`

Identifier fields were removed to prevent spurious correlations.

---

### 3.3 Preprocessing Strategy

A production-style pipeline was implemented using scikit-learn:

- **Numeric features**
  - median imputation
  - standardisation

- **Categorical features**
  - most-frequent imputation
  - one-hot encoding with unknown handling

All transformations are encapsulated in a `ColumnTransformer` to ensure reproducibility and prevent train/test contamination.

---

### 3.4 Model Selection

A **Logistic Regression** model was chosen as the baseline because:

- interpretability is critical for churn interventions
- coefficients provide direct business insight
- robust with limited behavioural history
- suitable for linearly separable signals

Class imbalance was addressed via:

- `class_weight="balanced"`
- evaluation focused on ROC-AUC and recall rather than accuracy

---

## 4. Results

### Performance (Test Set)

- **ROC-AUC ≈ 0.60**
- Churn recall ≈ 0.52
- Precision ≈ 0.24

The performance is realistic given:

- single-snapshot dataset
- limited longitudinal behaviour
- absence of tenure information

---

### Key Drivers of Churn

**Increased Risk**
- long time since last interaction
- low login frequency
- unresolved service issues
- complaint interactions
- low income segment

**Reduced Risk**
- frequent logins
- resolved issues
- website engagement
- higher income segment

These align with established retention theory and validate model credibility despite moderate AUC.

---

## 5. Limitations

- No historical sequences or tenure features
- Single record per customer
- No contract or pricing information
- No external economic signals

The model should therefore be viewed as a **baseline risk prioritisation tool**, not a definitive causal engine.

---

## 6. Project Structure

- `/src/eda.py` – exploratory analysis
- `/src/modeling.py` – full preprocessing & training pipeline
- `/plots/` – EDA visualisations
- `/reports/` – formal Task 1 & Task 2 documentation
- `/data/` – source dataset

---

## 7. How to Run

```bash
pip install -r requirements.txt
python src/eda.py
python src/modeling.py
